{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa38621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d9c357",
   "metadata": {},
   "source": [
    "# KNN Custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107f5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def euclidean(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Compute the Euclidean distance between two points.\n",
    "\n",
    "        Parameters:\n",
    "        x1 : numpy.ndarray, shape (n_features,)\n",
    "            The first point.\n",
    "        x2 : numpy.ndarray, shape (n_features,)\n",
    "            The second point.\n",
    "\n",
    "        Returns:\n",
    "        (float) :The Euclidean distance between x1 and x2.\n",
    "        \"\"\"\n",
    "        return np.sqrt(np.sum(np.square(x1 - x2)))\n",
    "\n",
    "    def manhattan(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Compute the Manhattan distance between two points.\n",
    "\n",
    "        Parameters:\n",
    "        x1 : numpy.ndarray, shape (n_features,)\n",
    "            The first point.\n",
    "        x2 : numpy.ndarray, shape (n_features,)\n",
    "            The second point.\n",
    "\n",
    "        Returns:\n",
    "        (float) : The Manhattan distance between x1 and x2.\n",
    "        \"\"\"\n",
    "        return np.sum(np.abs(x1 - x2))\n",
    "    \n",
    "    def __init__(self, n_neighbors=5, distance_metric='euclidean'):\n",
    "        \"\"\"\n",
    "        Constructor for KNN class.\n",
    "\n",
    "        Parameters:\n",
    "        n_neighbors (int): Number of nearest neighbors to consider for prediction.\n",
    "        distance_metric (str): Distance metric to use for computing distances between samples.\n",
    "                               Possible values are 'euclidean' and 'manhattan'. Default is 'euclidean'.\n",
    "        \"\"\"\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Method to fit the KNN model to training data.\n",
    "\n",
    "        Parameters:\n",
    "        X (numpy.ndarray): Training data of shape (n_samples, n_features).\n",
    "        y (numpy.ndarray): Target values of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Method to predict target values for given test data using the KNN model.\n",
    "\n",
    "        Parameters:\n",
    "        X (numpy.ndarray): Test data of shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "        y_pred (numpy.ndarray): Predicted target values of shape (n_samples,).\n",
    "        \"\"\"\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i, test_pt in enumerate(X):\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                # Compute Euclidean distances\n",
    "                distances = np.array([self.euclidean(test_pt, train_pt) for train_pt in self.X_train])\n",
    "            elif self.distance_metric == 'manhattan':\n",
    "                # Compute Manhattan distances\n",
    "                distances = np.array([self.manhattan(test_pt, train_pt) for train_pt in self.X_train])\n",
    "            else:\n",
    "                raise ValueError(\"Invalid distance metric specified. Please choose either 'euclidean' or 'manhattan'.\")\n",
    "\n",
    "            # Get indices of k-nearest neighbors\n",
    "            idx = np.argsort(distances)[:self.n_neighbors]\n",
    "\n",
    "            # Get labels of k-nearest neighbors\n",
    "            labels = self.y_train[idx]\n",
    "\n",
    "            # Predict label with majority vote\n",
    "            y_pred[i] = np.bincount(labels).argmax()\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0224174d",
   "metadata": {},
   "source": [
    "# Implementation Correctness - using artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05baa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation Correctness Report - using artificial dataset\n",
    "df = pd.read_csv('implementation_correctness_dataset.csv')\n",
    "\n",
    "X = df[['Feature 1', 'Feature 2']]\n",
    "y = df['Class/Cluster']\n",
    "testdata = {'Feature 1': [1.4], 'Feature 2': [3]}\n",
    "X_test = pd.DataFrame(testdata)\n",
    "test_point=X_test.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation Correctness Report - For Euclidean\n",
    "knn = KNN(n_neighbors=3, distance_metric='euclidean')\n",
    "knn.fit(X.values, y.values)\n",
    "\n",
    "y_pred = knn.predict(X_test.values)\n",
    "print('Using Euclidean distance, the test point is classified as class:', y_pred[0])\n",
    "\n",
    "# scatterplot of dataset\n",
    "plt.scatter(X.values[:, 0], X.values[:, 1], c=y)\n",
    "# scatterplot of test point\n",
    "plt.scatter(test_point[0], test_point[1], marker='x', color='black', label='Test Point')\n",
    "# scatterplot of 3 closest neighbors\n",
    "idx = np.argpartition(np.sqrt(((X - test_point)**2).sum(axis=1)), 3)[:3]\n",
    "plt.scatter(X.values[idx, 0], X.values[idx, 1], marker='o', color='red', facecolor='none', label='3 Closest Neighbors')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Scatter plot of the test point, its 3 nearest neighbors from dataset - using Euclidean dist')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation Correctness Report - For Manhattan\n",
    "knn2 = KNN(n_neighbors=3, distance_metric='manhattan')\n",
    "knn2.fit(X.values, y.values)\n",
    "y_pred = knn2.predict(X_test.values)\n",
    "print('Using Manhattan distance, the test point is classified as class:', y_pred[0])\n",
    "\n",
    "# scatterplot of dataset\n",
    "plt.scatter(X.values[:, 0], X.values[:, 1], c=y)\n",
    "# scatterplot of test point\n",
    "plt.scatter(test_point[0], test_point[1], marker='x', color='black', label='Test Point')\n",
    "# scatterplot of 3 closest neighbors\n",
    "\n",
    "idx = np.argpartition(np.abs(X - test_point).sum(axis=1), 3)[:3]\n",
    "plt.scatter(X.values[idx, 0], X.values[idx, 1], marker='o', color='red', facecolor='none', label='3 Closest Neighbors')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Scatter plot of the test point, its 3 nearest neighbors from dataset - using manhattan dist')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4a189",
   "metadata": {},
   "source": [
    "# Data Load, Preprocessing, training and testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15567e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load and Cleanup, training and testing split\n",
    "dataset = df = pd.read_csv(\"./data.csv\")\n",
    "df.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "print(df['diagnosis'].value_counts())\n",
    "df[\"diagnosis\"] = [1 if i.strip() == \"M\" else 0 for i in df.diagnosis]\n",
    "X=df.drop('diagnosis', axis=1, inplace=False)\n",
    "y=df[\"diagnosis\"]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30)\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e77ab7",
   "metadata": {},
   "source": [
    "# Vanilla KNN - Original Features for both distance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ba47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanilla KNN - using methods implemented from Scratch\n",
    "distances=['euclidean','manhattan']\n",
    "knnvalues=[]\n",
    "knnprecision=[]\n",
    "knnrecall=[]\n",
    "knnf1=[]\n",
    "\n",
    "for i, dtype in enumerate(distances):\n",
    "    knn = KNN(n_neighbors=10, distance_metric=dtype)\n",
    "    knn.fit(X_train.values, y_train.values)\n",
    "    knnvalues.append(accuracy_score(y_test,knn.predict(X_test.values))*100)\n",
    "    y_pred = knn.predict(X_test.values)\n",
    "    knnprecision.append(precision_score(y_test.values, y_pred)*100)\n",
    "    knnrecall.append(recall_score(y_test.values, y_pred)*100)\n",
    "    knnf1.append(f1_score(y_test.values, y_pred)*100)\n",
    "    \n",
    "    print(\"confusion matrix for method:\"+dtype)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"classification report for method:\"+dtype)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3b0d0",
   "metadata": {},
   "source": [
    "# KNN for AutoEncoder based feature representations i.e 5% of orginial number of features and 20% of original number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45427635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoEncoder Based Feature Representation\n",
    "#Configuration for autoencoder\n",
    "df_features = df.iloc[:,2:]\n",
    "n_features = df_features.shape[1]\n",
    "n_encoder1 = 500\n",
    "n_encoder2 = 300\n",
    "n_decoder2 = 300\n",
    "n_decoder1 = 500\n",
    "n_bottleneck_1 = int(math.ceil(n_features * 0.05))\n",
    "n_bottleneck_2 = int(math.ceil(n_features * 0.2))\n",
    "print(\"Bottleneck size 1: \",n_bottleneck_1)\n",
    "print(\"Bottleneck size 2: \",n_bottleneck_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d793e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration for autoencoder 5% of features\n",
    "reg5 = MLPRegressor(hidden_layer_sizes = (n_encoder1, n_encoder2, n_bottleneck_1, n_decoder2, n_decoder1),  \n",
    "                    solver = 'adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init = 0.001, \n",
    "                    max_iter = 1000,  \n",
    "                    verbose = False)\n",
    "reg5.fit(X_train.values, X_train.values)\n",
    "hidden_layer = reg5.hidden_layer_sizes[1]\n",
    "X_train_bottleneck_5 = reg5.predict(X_train)[:, :hidden_layer]\n",
    "X_test_bottleneck_5 = reg5.predict(X_test)[:, :hidden_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c079d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for autoEncoder 5% features- using methods implemented from Scratch\n",
    "distances=['euclidean','manhattan']\n",
    "ae5accuracy=[]\n",
    "ae5precision=[]\n",
    "ae5recall=[]\n",
    "ae5f1=[]\n",
    "\n",
    "    \n",
    "for i, dtype in enumerate(distances):\n",
    "    knn = KNN(n_neighbors=10, distance_metric=dtype)\n",
    "    knn.fit(X_train_bottleneck_5, y_train.values)\n",
    "    y_pred = knn.predict(X_test_bottleneck_5)\n",
    "    ae5accuracy.append(accuracy_score(y_test,y_pred)*100)\n",
    "    ae5precision.append(precision_score(y_test.values, y_pred)*100)\n",
    "    ae5recall.append(recall_score(y_test.values, y_pred)*100)\n",
    "    ae5f1.append(f1_score(y_test.values, y_pred)*100)\n",
    "    print(\"confusion matrix for method:\"+dtype)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"classification report for method:\"+dtype)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration for autoencoder 20% of features\n",
    "reg20 = MLPRegressor(hidden_layer_sizes = (n_encoder1, n_encoder2, n_bottleneck_2, n_decoder2, n_decoder1),  \n",
    "                    solver = 'adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init = 0.001, \n",
    "                    max_iter = 1000,  \n",
    "                    verbose = False)\n",
    "reg20.fit(X_train.values, X_train.values)\n",
    "hidden_layer = reg20.hidden_layer_sizes[1]\n",
    "X_train_bottleneck_20 = reg20.predict(X_train)[:, :hidden_layer]\n",
    "X_test_bottleneck_20 = reg20.predict(X_test)[:, :hidden_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cccbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for autoEncoder 20% features- using methods implemented from Scratchdistances=['euclidean','manhattan']\n",
    "ae20accuracy=[]\n",
    "ae20precision=[]\n",
    "ae20recall=[]\n",
    "ae20f1=[]\n",
    "\n",
    "for i, dtype in enumerate(distances):\n",
    "    knn = KNN(n_neighbors=10, distance_metric=dtype)\n",
    "    knn.fit(X_train_bottleneck_20, y_train.values)\n",
    "    y_pred = knn.predict(X_test_bottleneck_20)\n",
    "    ae20accuracy.append(accuracy_score(y_test.values, y_pred)*100)\n",
    "    ae20precision.append(precision_score(y_test.values, y_pred)*100)\n",
    "    ae20recall.append(recall_score(y_test.values, y_pred)*100)\n",
    "    ae20f1.append(f1_score(y_test.values, y_pred)*100)\n",
    "    print(\"confusion matrix for method:\"+dtype)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"classification report for method:\"+dtype)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7cfbe",
   "metadata": {},
   "source": [
    "# KNN for SVD low and SVD high feature representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singular Values\n",
    "svd = TruncatedSVD(n_components=30)\n",
    "svd.fit(X)\n",
    "plt.plot(svd.singular_values_)\n",
    "plt.xlabel(\"Rank, k\")\n",
    "plt.ylabel(\"Singular Values $S_k$\")\n",
    "plt.title(\"SVD Rank vs Singular Values\")\n",
    "#plt.savefig(\"svdknn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c164a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdlvalues=[]\n",
    "svdlprecision=[]\n",
    "svdlrecall=[]\n",
    "svdlf1=[]\n",
    "\n",
    "distances=['euclidean','manhattan']\n",
    "\n",
    "#SVD Low\n",
    "svd_low = TruncatedSVD(n_components=1)\n",
    "X_train_reduced_svd_low = svd_low.fit_transform(X_train, y_train)\n",
    "X_test_reduced_svd_low = svd_low.transform(X_test)\n",
    "print(\"Computing KNN From Scratch for SVD-Low\")\n",
    "for i, (dtype) in enumerate(distances):\n",
    "    knn = KNN(n_neighbors = 10, distance_metric = dtype)\n",
    "    knn.fit(X_train_reduced_svd_low, y_train.values)\n",
    "    svdlvalues.append(accuracy_score(y_test,knn.predict(X_test_reduced_svd_low))*100)\n",
    "    y_pred = knn.predict(X_test_reduced_svd_low)\n",
    "    svdlprecision.append(precision_score(y_test.values, y_pred)*100)\n",
    "    svdlrecall.append(recall_score(y_test.values, y_pred)*100)\n",
    "    svdlf1.append(f1_score(y_test.values, y_pred)*100)\n",
    "    print(\"confusion matrix for method:\"+dtype)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"classification report for method:\"+dtype)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "svdhvalues=[]\n",
    "svdhprecision=[]\n",
    "svdhrecall=[]\n",
    "svdhf1=[]\n",
    "\n",
    "distances=['euclidean','manhattan']\n",
    "\n",
    "print(\"Computing KNN From Scratch for SVD-High\")\n",
    "svd_high = TruncatedSVD(n_components=3)\n",
    "X_train_reduced_svd_high = svd_high.fit_transform(X_train, y_train)\n",
    "X_test_reduced_svd_high = svd_high.transform(X_test)\n",
    "for i, (dtype) in enumerate(distances):\n",
    "    knn = KNN(n_neighbors = 10, distance_metric = dtype)\n",
    "    knn.fit(X_train_reduced_svd_high, y_train.values)\n",
    "    svdhvalues.append(accuracy_score(y_test,knn.predict(X_test_reduced_svd_high))*100)\n",
    "    y_pred = knn.predict(X_test_reduced_svd_high)\n",
    "    svdhprecision.append(precision_score(y_test.values, y_pred)*100)\n",
    "    svdhrecall.append(recall_score(y_test.values, y_pred)*100)\n",
    "    svdhf1.append(f1_score(y_test.values, y_pred)*100)\n",
    "    print(\"confusion matrix for method:\"+dtype)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(\"classification report for method:\"+dtype)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd9150",
   "metadata": {},
   "source": [
    "# Comparison of various models (Combination of distance metrics, feature representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvals = ['Euclidean','Manhattan']\n",
    "X_axis = np.arange(len(Xvals))\n",
    "\n",
    "plt.bar(X_axis - 0.2, knnvalues, 0.4, label = 'No Reduction')\n",
    "plt.bar(X_axis - 0.1, svdlvalues, 0.4, label = 'SVD-Low')\n",
    "plt.bar(X_axis + 0.0, svdhvalues, 0.4, label = 'SVD-High')\n",
    "plt.bar(X_axis + 0.1, ae5accuracy, 0.4, label = 'MLP 5% of org features')\n",
    "plt.bar(X_axis + 0.2, ae20accuracy, 0.4, label = 'MLP 20% of org features')\n",
    "\n",
    "print(knnvalues)\n",
    "print(svdlvalues)\n",
    "print(svdhvalues)\n",
    "print(ae5accuracy)\n",
    "print(ae20accuracy)\n",
    "\n",
    "\n",
    "plt.xticks(X_axis, Xvals)\n",
    "plt.xlabel(\"Distances\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy score for different dimensionality reduction methods, k=10\")\n",
    "plt.ylim([70,100])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_axis - 0.2, knnprecision, 0.4, label = 'No Reduction')\n",
    "plt.bar(X_axis - 0.1, svdlprecision, 0.4, label = 'SVD-Low')\n",
    "plt.bar(X_axis + 0.0, svdhprecision, 0.4, label = 'SVD-High')\n",
    "plt.bar(X_axis + 0.1, ae5precision, 0.4, label = 'MLP 5% of org features')\n",
    "plt.bar(X_axis + 0.2, ae20precision, 0.4, label = 'MLP 20% of org features')\n",
    "\n",
    "print(knnprecision)\n",
    "print(svdlprecision)\n",
    "print(svdhprecision)\n",
    "print(ae5precision)\n",
    "print(ae20precision)\n",
    "\n",
    "plt.xticks(X_axis, Xvals)\n",
    "plt.xlabel(\"Distances\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision for different dimensionality reduction methods, k=10\")\n",
    "plt.ylim([70,100])\n",
    "plt.legend()\n",
    "#plt.savefig(\"PrecisionComparison\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_axis - 0.2, knnrecall, 0.4, label = 'No Reduction')\n",
    "plt.bar(X_axis - 0.1, svdlrecall, 0.4, label = 'SVD-Low')\n",
    "plt.bar(X_axis + 0.0, svdhrecall, 0.4, label = 'SVD-High')\n",
    "plt.bar(X_axis + 0.1, ae5recall, 0.4, label = 'MLP 5% of org features')\n",
    "plt.bar(X_axis + 0.2, ae20recall, 0.4, label = 'MLP 20% of org features')\n",
    "\n",
    "print(knnrecall)\n",
    "print(svdlrecall)\n",
    "print(svdhrecall)\n",
    "print(ae5recall)\n",
    "print(ae20recall)\n",
    "\n",
    "plt.xticks(X_axis, Xvals)\n",
    "plt.xlabel(\"Distances\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.title(\"Recall for different dimensionality reduction methods, k=10\")\n",
    "plt.ylim([70,100])\n",
    "plt.legend()\n",
    "#plt.savefig(\"RecallComparison\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(X_axis - 0.2, knnf1, 0.4, label = 'No Reduction')\n",
    "plt.bar(X_axis - 0.1, svdlf1, 0.4, label = 'SVD-Low')\n",
    "plt.bar(X_axis + 0.0, svdhf1, 0.4, label = 'SVD-High')\n",
    "plt.bar(X_axis + 0.1, ae5f1, 0.4, label = 'MLP 5% of org features')\n",
    "plt.bar(X_axis + 0.2, ae20f1, 0.4, label = 'MLP 20% of org features')\n",
    "\n",
    "\n",
    "print(knnf1)\n",
    "print(svdlf1)\n",
    "print(svdhf1)\n",
    "print(ae5f1)\n",
    "print(ae20f1)\n",
    "\n",
    "plt.xticks(X_axis, Xvals)\n",
    "plt.xlabel(\"Distances\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 score for different dimensionality reduction methods, k=10\")\n",
    "plt.ylim([70,100])\n",
    "plt.legend()\n",
    "#plt.savefig(\"f1Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2ae523",
   "metadata": {},
   "source": [
    "# K-Fold Cross validation of various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a465415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(data, labels, k, knn):\n",
    "    \"\"\"\n",
    "    Performs k-fold cross-validation on the KNN model.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy array): The data to be used for cross-validation.\n",
    "    labels (numpy array): The labels corresponding to the data.\n",
    "    k (int): The number of folds to use.\n",
    "    knn (object): An instance of your KNN implementation.\n",
    "\n",
    "    Returns:\n",
    "    float: The average accuracy across all folds.\n",
    "    float: The standard deviation of the accuracy across all folds.\n",
    "    float: The average precision across all folds.\n",
    "    float: The standard deviation of the precision across all folds.\n",
    "    float: The average recall across all folds.\n",
    "    float: The standard deviation of the recall across all folds.\n",
    "    float: The average F1 score across all folds.\n",
    "    float: The standard deviation of the F1 score across all folds.\n",
    "    \"\"\"\n",
    "    fold_size = len(data) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "\n",
    "        test_data = data[start:end]\n",
    "        test_labels = labels[start:end]\n",
    "\n",
    "        train_data = np.concatenate([data[:start], data[end:]])\n",
    "        train_labels = np.concatenate([labels[:start], labels[end:]])\n",
    "\n",
    "        knn.fit(train_data, train_labels)\n",
    "        predictions = knn.predict(test_data)\n",
    "\n",
    "        accuracy = accuracy_score(test_labels, predictions)\n",
    "        precision = precision_score(test_labels, predictions)\n",
    "        recall = recall_score(test_labels, predictions)\n",
    "        f1score = f1_score(test_labels, predictions)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1score)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    mean_precision = np.mean(precisions)\n",
    "    std_precision = np.std(precisions)\n",
    "    mean_recall = np.mean(recalls)\n",
    "    std_recall = np.std(recalls)\n",
    "    mean_f1_score = np.mean(f1_scores)\n",
    "    std_f1_score = np.std(f1_scores)\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e666a",
   "metadata": {},
   "source": [
    "## KNN original features - K Fold Cross validation with Hyperperformance tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ea944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanilla KNN\n",
    "n_folds = 10\n",
    "k_vals = range(1, 31)\n",
    "dist_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "maxF1=0\n",
    "maxRecall=0\n",
    "maxPrecision=0\n",
    "maxk=0\n",
    "maxDmetric='nil'\n",
    "maxFeatureRep='nil'\n",
    "recallOfMaxE=0\n",
    "precisionOfMax=0\n",
    "accuracyOfMax=0\n",
    "for metric in dist_metrics:\n",
    "    # initialize lists to store results\n",
    "    accuracy_means = []\n",
    "    accuracy_stds = []\n",
    "    precision_means = []\n",
    "    precision_stds = []\n",
    "    recall_means = []\n",
    "    recall_stds = []\n",
    "    f1_score_means = []\n",
    "    f1_score_stds = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "        # initialize KNN model\n",
    "        knn = KNN(n_neighbors=k, distance_metric=metric)\n",
    "        \n",
    "        mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = k_fold_cross_validation(X_scaled, y.values, 10, knn)\n",
    "\n",
    "        # calculate mean and standard deviation of fold results\n",
    "        accuracy_means.append(mean_accuracy)\n",
    "        accuracy_stds.append(std_accuracy)\n",
    "        precision_means.append(mean_precision)\n",
    "        precision_stds.append(std_precision)\n",
    "        recall_means.append(mean_recall)\n",
    "        recall_stds.append(std_recall)\n",
    "        f1_score_means.append(mean_f1_score)\n",
    "        f1_score_stds.append(std_f1_score)\n",
    "        \n",
    "    # plot results\n",
    "    #fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, accuracy_means, yerr=accuracy_stds, capsize=10)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(str(uuid.uuid4()))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, precision_means, yerr=precision_stds, capsize=10)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(str(uuid.uuid4()))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, recall_means, yerr=recall_stds, capsize=10)\n",
    "    plt.ylabel('Recall Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(str(uuid.uuid4()))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, f1_score_means, yerr=f1_score_stds, capsize=10)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(str(uuid.uuid4()))\n",
    "    plt.show()\n",
    "    \n",
    "    if(max(f1_score_means)>maxF1):\n",
    "        maxF1=max(f1_score_means)\n",
    "        maxk=f1_score_means.index(max(f1_score_means))+1\n",
    "        maxDmetric=metric\n",
    "        maxFeatureRep='Vanilla'\n",
    "        recallOfMaxE=recall_means[f1_score_means.index(max(f1_score_means))]\n",
    "        precisionOfMax=precision_means[f1_score_means.index(max(f1_score_means))]\n",
    "        accuracyOfMax=accuracy_means[f1_score_means.index(max(f1_score_means))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e078d8f6",
   "metadata": {},
   "source": [
    "## KNN SVD Low - K Fold Cross validation with Hyperperformance tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with SVD low\n",
    "n_folds = 10\n",
    "k_vals = range(1, 31)\n",
    "dist_metrics = ['euclidean', 'manhattan']\n",
    "svd_low = TruncatedSVD(n_components=1)\n",
    "X_svd_low = svd_low.fit_transform(X,y)\n",
    "\n",
    "for metric in dist_metrics:\n",
    "    # initialize lists to store results\n",
    "    accuracy_means = []\n",
    "    accuracy_stds = []\n",
    "    precision_means = []\n",
    "    precision_stds = []\n",
    "    recall_means = []\n",
    "    recall_stds = []\n",
    "    f1_score_means = []\n",
    "    f1_score_stds = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "        # initialize KNN model\n",
    "        knn = KNN(n_neighbors=k, distance_metric=metric)\n",
    "        \n",
    "        mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = k_fold_cross_validation(X_svd_low, y.values, 10, knn)\n",
    "\n",
    "        # calculate mean and standard deviation of fold results\n",
    "        accuracy_means.append(mean_accuracy)\n",
    "        accuracy_stds.append(std_accuracy)\n",
    "        precision_means.append(mean_precision)\n",
    "        precision_stds.append(std_precision)\n",
    "        recall_means.append(mean_recall)\n",
    "        recall_stds.append(std_recall)\n",
    "        f1_score_means.append(mean_f1_score)\n",
    "        f1_score_stds.append(std_f1_score)\n",
    "        \n",
    "    # plot results\n",
    "    #fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, accuracy_means, yerr=accuracy_stds, capsize=10)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"AccuracySVDLOW\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, precision_means, yerr=precision_stds, capsize=10)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"PrecisionSVDLOW\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, recall_means, yerr=recall_stds, capsize=10)\n",
    "    plt.ylabel('Recall Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"RecallSVDLOW\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, f1_score_means, yerr=f1_score_stds, capsize=10)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"F1SVDLOW\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    if(max(f1_score_means)>maxF1):\n",
    "        maxF1=max(f1_score_means)\n",
    "        maxk=f1_score_means.index(max(f1_score_means))+1\n",
    "        maxDmetric=metric\n",
    "        maxFeatureRep='SVD LOW'\n",
    "        recallOfMaxE=recall_means[f1_score_means.index(max(f1_score_means))]\n",
    "        precisionOfMax=precision_means[f1_score_means.index(max(f1_score_means))]\n",
    "        accuracyOfMax=accuracy_means[f1_score_means.index(max(f1_score_means))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b9b82",
   "metadata": {},
   "source": [
    "## KNN SVD HIGH - K Fold Cross validation with Hyperperformance tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bfdf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with SVD High\n",
    "n_folds = 10\n",
    "k_vals = range(1, 31)\n",
    "dist_metrics = ['euclidean', 'manhattan']\n",
    "svd_high = TruncatedSVD(n_components=3)\n",
    "X_svd_high = svd_high.fit_transform(X,y)\n",
    "\n",
    "for metric in dist_metrics:\n",
    "    # initialize lists to store results\n",
    "    accuracy_means = []\n",
    "    accuracy_stds = []\n",
    "    precision_means = []\n",
    "    precision_stds = []\n",
    "    recall_means = []\n",
    "    recall_stds = []\n",
    "    f1_score_means = []\n",
    "    f1_score_stds = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "        # initialize KNN model\n",
    "        knn = KNN(n_neighbors=k, distance_metric=metric)\n",
    "        \n",
    "        mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = k_fold_cross_validation(X_svd_high, y.values, 10, knn)\n",
    "\n",
    "        # calculate mean and standard deviation of fold results\n",
    "        accuracy_means.append(mean_accuracy)\n",
    "        accuracy_stds.append(std_accuracy)\n",
    "        precision_means.append(mean_precision)\n",
    "        precision_stds.append(std_precision)\n",
    "        recall_means.append(mean_recall)\n",
    "        recall_stds.append(std_recall)\n",
    "        f1_score_means.append(mean_f1_score)\n",
    "        f1_score_stds.append(std_f1_score)\n",
    "        \n",
    "    # plot results\n",
    "    #fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, accuracy_means, yerr=accuracy_stds, capsize=10)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"AccSVDHI\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, precision_means, yerr=precision_stds, capsize=10)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"PrecisionSVDHI\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, recall_means, yerr=recall_stds, capsize=10)\n",
    "    plt.ylabel('Recall Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"RecallSVDHI\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, f1_score_means, yerr=f1_score_stds, capsize=10)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"F1SVDHI\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    if(max(f1_score_means)>maxF1):\n",
    "        maxF1=max(f1_score_means)\n",
    "        maxk=f1_score_means.index(max(f1_score_means))+1\n",
    "        maxDmetric=metric\n",
    "        maxFeatureRep='SVD High'\n",
    "        recallOfMaxE=recall_means[f1_score_means.index(max(f1_score_means))]\n",
    "        precisionOfMax=precision_means[f1_score_means.index(max(f1_score_means))]\n",
    "        accuracyOfMax=accuracy_means[f1_score_means.index(max(f1_score_means))]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378d12e",
   "metadata": {},
   "source": [
    "## KNN AutoEncode 5% org. features - K Fold Cross validation with Hyperperformance tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with AutoEncoder 5% of features\n",
    "n_folds = 10\n",
    "k_vals = range(1, 31)\n",
    "dist_metrics = ['euclidean', 'manhattan']\n",
    "#Configuration for autoencoder 5% of features\n",
    "reg5 = MLPRegressor(hidden_layer_sizes = (n_encoder1, n_encoder2, n_bottleneck_1, n_decoder2, n_decoder1),  \n",
    "                    solver = 'adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init = 0.001, \n",
    "                    max_iter = 1000,  \n",
    "                    verbose = False)\n",
    "reg5.fit(X.values, X.values)\n",
    "hidden_layer = reg5.hidden_layer_sizes[1]\n",
    "X_bottleneck_5 = reg5.predict(X.values)[:, :hidden_layer]\n",
    "\n",
    "\n",
    "for metric in dist_metrics:\n",
    "    # initialize lists to store results\n",
    "    accuracy_means = []\n",
    "    accuracy_stds = []\n",
    "    precision_means = []\n",
    "    precision_stds = []\n",
    "    recall_means = []\n",
    "    recall_stds = []\n",
    "    f1_score_means = []\n",
    "    f1_score_stds = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "        # initialize KNN model\n",
    "        knn = KNN(n_neighbors=k, distance_metric=metric)\n",
    "        \n",
    "        mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = k_fold_cross_validation(X_bottleneck_5, y.values, 10, knn)\n",
    "\n",
    "        # calculate mean and standard deviation of fold results\n",
    "        accuracy_means.append(mean_accuracy)\n",
    "        accuracy_stds.append(std_accuracy)\n",
    "        precision_means.append(mean_precision)\n",
    "        precision_stds.append(std_precision)\n",
    "        recall_means.append(mean_recall)\n",
    "        recall_stds.append(std_recall)\n",
    "        f1_score_means.append(mean_f1_score)\n",
    "        f1_score_stds.append(std_f1_score)\n",
    "        \n",
    "    # plot results\n",
    "    #fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, accuracy_means, yerr=accuracy_stds, capsize=10)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"accae5\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, precision_means, yerr=precision_stds, capsize=10)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"precae5\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, recall_means, yerr=recall_stds, capsize=10)\n",
    "    plt.ylabel('Recall Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"recallae5\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, f1_score_means, yerr=f1_score_stds, capsize=10)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"F1ae5\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    if(max(f1_score_means)>maxF1):\n",
    "        maxF1=max(f1_score_means)\n",
    "        maxk=f1_score_means.index(max(f1_score_means))+1\n",
    "        maxDmetric=metric\n",
    "        maxFeatureRep='AE 5%'\n",
    "        recallOfMaxE=recall_means[f1_score_means.index(max(f1_score_means))]\n",
    "        precisionOfMax=precision_means[f1_score_means.index(max(f1_score_means))]\n",
    "        accuracyOfMax=accuracy_means[f1_score_means.index(max(f1_score_means))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec17fbb",
   "metadata": {},
   "source": [
    "## KNN AutoEncode 20% org. features - K Fold Cross validation with Hyperperformance tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34866b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with AutoEncoder 20% of features\n",
    "n_folds = 10\n",
    "k_vals = range(1, 31)\n",
    "dist_metrics = ['euclidean', 'manhattan']\n",
    "#Configuration for autoencoder 5% of features\n",
    "reg20 = MLPRegressor(hidden_layer_sizes = (n_encoder1, n_encoder2, n_bottleneck_2, n_decoder2, n_decoder1),  \n",
    "                    solver = 'adam',\n",
    "                    activation='relu',\n",
    "                    learning_rate_init = 0.001, \n",
    "                    max_iter = 1000,  \n",
    "                    verbose = False)\n",
    "reg20.fit(X.values, X.values)\n",
    "hidden_layer = reg20.hidden_layer_sizes[1]\n",
    "X_bottleneck_20 = reg20.predict(X.values)[:, :hidden_layer]\n",
    "\n",
    "\n",
    "for metric in dist_metrics:\n",
    "    # initialize lists to store results\n",
    "    accuracy_means = []\n",
    "    accuracy_stds = []\n",
    "    precision_means = []\n",
    "    precision_stds = []\n",
    "    recall_means = []\n",
    "    recall_stds = []\n",
    "    f1_score_means = []\n",
    "    f1_score_stds = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "        # initialize KNN model\n",
    "        knn = KNN(n_neighbors=k, distance_metric=metric)\n",
    "        \n",
    "        mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = k_fold_cross_validation(X_bottleneck_20, y.values, 10, knn)\n",
    "\n",
    "        # calculate mean and standard deviation of fold results\n",
    "        accuracy_means.append(mean_accuracy)\n",
    "        accuracy_stds.append(std_accuracy)\n",
    "        precision_means.append(mean_precision)\n",
    "        precision_stds.append(std_precision)\n",
    "        recall_means.append(mean_recall)\n",
    "        recall_stds.append(std_recall)\n",
    "        f1_score_means.append(mean_f1_score)\n",
    "        f1_score_stds.append(std_f1_score)\n",
    "        \n",
    "    # plot results\n",
    "    #fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, accuracy_means, yerr=accuracy_stds, capsize=10)\n",
    "    plt.ylabel('Accuracy Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"accae20\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, precision_means, yerr=precision_stds, capsize=10)\n",
    "    plt.ylabel('Precision Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"precae20\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, recall_means, yerr=recall_stds, capsize=10)\n",
    "    plt.ylabel('Recall Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"recallae20\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.errorbar(k_vals, f1_score_means, yerr=f1_score_stds, capsize=10)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xlabel('K neighbors')\n",
    "    plt.ylim(0.5, 1.2)\n",
    "    plt.xticks(k_vals)\n",
    "    plt.title(f'K-Fold Cross Validation - {metric}')\n",
    "    #plt.savefig(\"F1ae20\"+metric)\n",
    "    plt.show()\n",
    "    \n",
    "    if(max(f1_score_means)>maxF1):\n",
    "        maxF1=max(f1_score_means)\n",
    "        maxk=f1_score_means.index(max(f1_score_means))+1\n",
    "        maxDmetric=metric\n",
    "        maxFeatureRep='AE 20%'\n",
    "        recallOfMaxE=recall_means[f1_score_means.index(max(f1_score_means))]\n",
    "        precisionOfMax=precision_means[f1_score_means.index(max(f1_score_means))]\n",
    "        accuracyOfMax=accuracy_means[f1_score_means.index(max(f1_score_means))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdf59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best performance detected for :\")\n",
    "print(\"F1 Score:\")\n",
    "print(maxF1)\n",
    "print(\"Precision: \")\n",
    "print(recallOfMaxE)\n",
    "print(\"Recall: \")\n",
    "print(precisionOfMax)\n",
    "print(\"Accuracy: \")\n",
    "print(accuracyOfMax)\n",
    "print(\"K: \")\n",
    "print(maxk)\n",
    "print(\"Distance: \")\n",
    "print(maxDmetric)\n",
    "print(\"Feature Rep: \")\n",
    "print(maxFeatureRep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e6965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
